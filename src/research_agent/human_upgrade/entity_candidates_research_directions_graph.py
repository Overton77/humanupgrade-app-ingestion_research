"""
Candidate and Research Directions Graph for Entity Intel 
"""

from langgraph.graph import StateGraph, START, END   
from langgraph.graph.state import CompiledStateGraph 
from datetime import datetime

from typing_extensions import TypedDict
from typing import  Dict, Any, List

from langchain.agents import create_agent  
from dotenv import load_dotenv 
from langchain.agents.structured_output import ProviderStrategy 
from langchain.agents.middleware import SummarizationMiddleware
from research_agent.human_upgrade.structured_outputs.research_direction_outputs import ( 
    EntityBundlesListOutputA,
    EntityBundlesListFinal,
    compile_bundles_list, 
    EntityBundleDirectionsFinal,
) 
from research_agent.human_upgrade.structured_outputs.candidates_outputs import ( 
 
    CandidateSourcesConnected,
   SeedExtraction,
)   
from langchain_core.runnables import RunnableConfig
from langchain.tools import BaseTool 

from research_agent.human_upgrade.logger import logger
from research_agent.human_upgrade.utils.artifacts import save_json_artifact, save_text_artifact 
from research_agent.human_upgrade.prompts.seed_prompts import PROMPT_OUTPUT_A_SEED_EXTRACTION
from research_agent.human_upgrade.prompts.candidates_prompts import PROMPT_OUTPUT_A2_CONNECTED_CANDIDATE_SOURCES
from research_agent.human_upgrade.prompts.research_directions_prompts import PROMPT_OUTPUT_A3_ENTITY_RESEARCH_DIRECTIONS
from research_agent.clients.langsmith_client import pull_prompt_from_langsmith 
from research_agent.human_upgrade.tools.web_search_tools import (
    wiki_tool, 
    tavily_map_validation, 
    tavily_search_validation,
    tavily_extract_validation, 
    
) 

from research_agent.human_upgrade.utils.formatting import format_seed_extraction_for_prompt, format_connected_candidates_for_prompt 
from research_agent.human_upgrade.intel_mongo_nodes import ( 
    persist_candidates_node, 
    persist_research_plans_node,
)

from research_agent.human_upgrade.base_models import gpt_4_1, gpt_5_mini, gpt_5_nano, gpt_5  
from research_agent.human_upgrade.persistence.checkpointer_and_store import get_persistence
import os 

load_dotenv() 

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY") 

openai_search_tool: Dict[str, str] = {"type": "web_search"}  



pull_prompt_names: Dict[str, str] = { 
    "seed_extraction_prompt": "seed_extraction_prompt", 
    "connected_candidate_sources_prompt": "connected_candidate_sources_prompt",
    "research_directions_prompt": "research_directions_prompt",
}


class EntityIntelCandidateAndResearchDirectionsState(TypedDict, total=False):
    """State for a single entity candidate and research directions."""
    # Core tool-loop plumbing
    llm_calls: int
    tool_calls: int

    # Episode context
    episode: Dict[str, Any]

    # Existing outputs
    seed_extraction: SeedExtraction
    candidate_sources: CandidateSourcesConnected
    research_directions: EntityBundlesListFinal

    # ----------------------------
    # NEW: Intel orchestration
    # ----------------------------

    # Stable per-run identifiers (set once, reused across nodes)
    intel_run_id: str
    intel_pipeline_version: str

    # Outputs from persist_candidates_node
    candidate_entity_ids: List[str]          # candidateEntityId values inserted for this run
    dedupe_group_map: Dict[str, str]         # entityKey -> dedupeGroupId

    # Outputs from persist_research_plans_node
    research_plan_ids: List[str]             # planId values inserted

    # Optional: error capture if you want
    error: str

    steps_taken: int
    



VALIDATION_TOOLS: List[BaseTool] = [
    wiki_tool,
    tavily_search_validation,
    tavily_extract_validation,
    tavily_map_validation,
]




async def seed_extraction_node(state: EntityIntelCandidateAndResearchDirectionsState) -> EntityIntelCandidateAndResearchDirectionsState:  
    episode: Dict[str, Any] = state.get("episode", {})
    webpage_summary: str = episode.get("webPageSummary") 
    episode_url: str = episode.get("episodePageUrl")
    
    if not webpage_summary:
        raise ValueError("episode.webPageSummary is required")
    if not episode_url:
        raise ValueError("episode.episodePageUrl is required")
    
    logger.info(f"ðŸŒ± Starting seed extraction for episode: {episode_url[:80]}...")   

    seed_extraction_prompt: str = PROMPT_OUTPUT_A_SEED_EXTRACTION.format(
        episode_url=episode_url,
        webpage_summary=webpage_summary,
    )  

    seed_extraction_agent: CompiledStateGraph = create_agent(   
     
        gpt_5_mini,   
        tools=[openai_search_tool], 
        response_format=ProviderStrategy(SeedExtraction),  
           name="seed_extraction_agent",
    ) 

    response = await seed_extraction_agent.ainvoke( 
        {"messages": [{"role": "user", "content": seed_extraction_prompt}]} 
    ) 

    seed_extraction_output: SeedExtraction = response["structured_response"]
    
    logger.info(
        "âœ… Seed extraction complete: guests=%s businesses=%s products=%s compounds=%s platforms=%s",
        len(seed_extraction_output.guest_candidates) if seed_extraction_output.guest_candidates else 0,
        len(seed_extraction_output.business_candidates) if seed_extraction_output.business_candidates else 0,
        len(seed_extraction_output.product_candidates) if seed_extraction_output.product_candidates else 0,
        len(seed_extraction_output.compound_candidates) if seed_extraction_output.compound_candidates else 0,
        len(seed_extraction_output.platform_candidates) if seed_extraction_output.platform_candidates else 0,
    )

    return { 
        "seed_extraction": seed_extraction_output,
    }  


async def candidate_sources_node(state: EntityIntelCandidateAndResearchDirectionsState) -> EntityIntelCandidateAndResearchDirectionsState:
    seed_extraction: SeedExtraction = state.get("seed_extraction")
    if seed_extraction is None:
        logger.error("âŒ seed_extraction is None in candidate_sources_node")
        raise ValueError("seed_extraction is required but was not found in state")

    episode_url: str = (state.get("episode") or {}).get("episodePageUrl", "unknown")

    logger.info(
        "ðŸ“‹ Processing candidate sources: guests=%s businesses=%s products=%s",
        len(seed_extraction.guest_candidates),
        len(seed_extraction.business_candidates),
        len(seed_extraction.product_candidates),
    )

    formatted_fields: Dict[str, str] = format_seed_extraction_for_prompt(seed_extraction)

    candidate_sources_prompt: str = PROMPT_OUTPUT_A2_CONNECTED_CANDIDATE_SOURCES.format(
        episode_url=episode_url,
        guest_candidates=formatted_fields["guest_candidates"],
        business_candidates=formatted_fields["business_candidates"],
        product_candidates=formatted_fields["product_candidates"],
        platform_candidates=formatted_fields["platform_candidates"],
        compound_candidates=formatted_fields["compound_candidates"],
        evidence_claim_hooks=formatted_fields["evidence_claim_hooks"],
        notes=formatted_fields["notes"],
    )

    candidate_sources_agent: CompiledStateGraph = create_agent(
        gpt_5_mini,
        tools=VALIDATION_TOOLS,
        response_format=ProviderStrategy(CandidateSourcesConnected),
        middleware=[
            SummarizationMiddleware(
                model="gpt-4.1",
                trigger=("tokens", 170000),
                keep=("messages", 20),
            )
        ],
        name="candidate_sources_agent",
    )

    response = await candidate_sources_agent.ainvoke(
        {"messages": [{"role": "user", "content": candidate_sources_prompt}]}
    )

    candidate_sources_output: CandidateSourcesConnected = response["structured_response"]

    logger.info("âœ… Candidate sources complete: connected_bundles=%s", len(candidate_sources_output.connected))

    try:
        await save_json_artifact(
            candidate_sources_output.model_dump(),
            "test_run",
            "candidate_sources_connected",
            suffix=episode_url.replace("/", "_")[:30],
        )
    except Exception as e:
        return {
            "candidate_sources": candidate_sources_output,
            "error": str(e),
        }

    # Return partial state update (LangGraph merges it)
    return {
        "candidate_sources": candidate_sources_output,
    }


async def generate_research_directions_node(state: EntityIntelCandidateAndResearchDirectionsState) -> EntityIntelCandidateAndResearchDirectionsState:
    """
    Generate structured research directions from connected candidate sources.
    
    Step 1: LLM generates EntityBundlesListOutputA (objectives + starter sources for each bundle)
    Step 2: We compile to EntityBundlesListFinal (add deterministic required fields)
    """
    candidate_sources: CandidateSourcesConnected = state.get("candidate_sources", CandidateSourcesConnected(connected=[]))
    if not candidate_sources.connected:
        logger.error("âŒ candidate_sources is None in research_directions_node")
        raise ValueError("candidate_sources is required but was not found in state")

    episode: Dict[str, Any] = state.get("episode", {})
    episode_url: str = episode.get("episodePageUrl", "unknown")
    
    logger.info(
        "ðŸŽ¯ Generating research directions for %s connected bundles",
        len(candidate_sources.connected)
    )

    # Format connected candidates for the prompt
    formatted_bundles: str = format_connected_candidates_for_prompt(candidate_sources)

    research_directions_prompt: str = PROMPT_OUTPUT_A3_ENTITY_RESEARCH_DIRECTIONS.format(
        connected_bundles=formatted_bundles,
    )

    
    research_directions_agent: CompiledStateGraph = create_agent(
        gpt_5_mini,
        response_format=ProviderStrategy(EntityBundlesListOutputA), 
        name="research_directions_agent",
    )

    response = await research_directions_agent.ainvoke(
        {"messages": [{"role": "user", "content": research_directions_prompt}]}
    )

    bundles_list_output_a: EntityBundlesListOutputA = response["structured_response"]  



    logger.info(
        "âœ… LLM OutputA complete: %s bundles with objectives and starter sources",
        len(bundles_list_output_a.bundles),
    ) 

    compiled_bundles_list: EntityBundlesListFinal = compile_bundles_list(bundles_list_output_a) 

    await save_json_artifact(
        compiled_bundles_list.model_dump(),
        "test_run",
        "research_directions_compiled_bundles_list",
        suffix=episode_url.replace("/", "_")[:30] + "_" + datetime.now().strftime("%Y%m%d_%H%M%S"),
    )
    
    logger.info(
        "âœ… Research directions complete: %s bundles compiled with required fields",
        len(compiled_bundles_list.bundles)
    )

    return {
        "research_directions": compiled_bundles_list,
    }









# ============================================================================
# BUILD SUBGRAPH
# ============================================================================

def build_entity_research_directions_builder() -> StateGraph:
    builder: StateGraph = StateGraph(EntityIntelCandidateAndResearchDirectionsState)

    builder.add_node("seed_extraction", seed_extraction_node)
    builder.add_node("candidate_sources", candidate_sources_node)
    builder.add_node("generate_research_directions", generate_research_directions_node)
    builder.add_node("persist_candidates", persist_candidates_node)
    builder.add_node("persist_research_plans", persist_research_plans_node)
    builder.set_entry_point("seed_extraction")
    builder.add_edge("seed_extraction", "candidate_sources") 
    builder.add_edge("candidate_sources", "persist_candidates")  
    builder.add_edge("candidate_sources", "generate_research_directions") 
    builder.add_edge("generate_research_directions", "persist_research_plans")
    builder.add_edge("generate_research_directions", END)

    return builder



async def make_entity_research_directions_graph(config: RunnableConfig) -> CompiledStateGraph:
    """
    Graph factory for LangSmith Studio / LangGraph CLI.
    Called per run; we reuse process-wide store/checkpointer.
    """
    store, checkpointer = await get_persistence()

    # IMPORTANT: checkpoint namespace is provided at runtime via config["configurable"]["checkpoint_ns"]
    # so compile once with the saver; per-run separation happens via config.
    graph: CompiledStateGraph = build_entity_research_directions_builder().compile(
        checkpointer=checkpointer,
        store=store,
    )
    return graph